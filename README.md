# Building-Agentic-AI-Project-01

# Generative AI Project Template

## ğŸš€ Quick Start
```bash
# Clone repository
git clone https://github.com/mayankchugh-learning/your-project-name.git
cd your-project-name

# Create virtual environment
cmd
set PATH=%PATH%;C:\Users\madfa\.local\bin

# Verify installation
uv --version
uv self version
# View uv help
uv


uv --version
uv self version
python -m venv env

# Project Setup
# Initialize a new project
uv init 

# Create virtual environment
uv venv

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
uv add -r requirements.txt
pip install -r requirements.txt

# Set API keys (create .env file)
echo "OPENAI_API_KEY=your_api_key_here" > .env

# Run application
python main.py

ğŸ“¦ Prerequisites
Python 3.7+
pip package manager
API keys for services (OpenAI, Hugging Face, etc.)
ğŸ› ï¸ Project Structure
basic
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ main.py                 # Main application script
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ agents/             # AI agent implementations
â”‚   â”œâ”€â”€ utils/              # Helper functions
â”‚   â””â”€â”€ workflows/          # LangChain/LangGraph workflows
â”œâ”€â”€ data/                   # Sample datasets
â””â”€â”€ notebooks/              # Jupyter notebooks

ğŸ”§ Requirements
ipykernel
dotenv
langchain
langchain_community
langchain_openai
langchain_google_genai
langchain_core
langgraph
youtube-search-python
youtube-search
langchain-ollama
langchain_huggingface

ğŸŒ Environment Setup
Create .env file with your API keys:
ini
OPENAI_API_KEY=your_openai_key
HUGGINGFACE_TOKEN=your_hf_token
ANYSCALE_API_KEY=your_anyscale_key

For GPU acceleration (optional):
bash
pip install torch==2.3.0 --index-url https://download.pytorch.org/whl/cu121

ğŸ—ï¸ Advanced Setup
Using UV Package Manager
bash
uv pip install -r requirements.txt

Docker Setup
dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install --no-cache-dir -r requirements.txt
CMD ["python", "main.py"]

ğŸ’» Execution Options
Method	Command	Use Case
CLI	python main.py	Production runs
Jupyter	jupyter notebook	Experimentation
Docker	docker build -t ai-app .	Container deployment
ğŸ¤– Sample Workflow (main.py)
python

View all
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()

def main():
    llm = ChatOpenAI(model="gpt-4-turbo")
    response = llm.invoke("Explain quantum computing simply")
    print(response.content)

if __name__ == "__main__":
    main()

Run

ğŸ“š Additional Resources
I would like to invite you to explore my Generative AI work on the "IT AI Enthusiast" YouTube channel. Our content features informative tutorials, case studies, and hands-on projects that make complex AI concepts accessible and engaging.
Connect with me through these platforms:

ğŸ¥ YouTube Channel: Tutorials and project walkthroughs
ğŸ¤— Hugging Face: Live AI demos and spaces
ğŸ’» GitHub: Source code and projects
âœï¸ Medium: Technical articles and guides
ğŸ‘” LinkedIn: Professional network
Your feedback would be greatly appreciated!

âš ï¸ Troubleshooting
Common issues:

ModuleNotFoundError:
bash
pip install --upgrade -r requirements.txt

Authentication errors:
Verify .env file exists in root directory
Confirm API keys have proper permissions
CUDA errors:
bash
pip uninstall torch && pip install torch --index-url https://download.pytorch.org/whl/cu121

ğŸ“œ License
This project is licensed under the MIT License - see the LICENSE file for details.